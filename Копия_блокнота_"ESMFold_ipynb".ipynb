{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhondamirRustamov/Neyron_tizimlarga-Kirish/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22ESMFold_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ESMFold**\n",
        "for more details see: [Github](https://github.com/facebookresearch/esm/tree/main/esm), [Preprint](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1)\n",
        "\n",
        "#### **Tips and Instructions**\n",
        "- click the little ▶ play icon to the left of each cell below.\n",
        "- use \"/\" to specify chainbreaks, (eg. sequence=\"AAA/AAA\")\n",
        "- for homo-oligomeric predictions, set copies > 1\n",
        "- See [experimental notebook](https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/beta/ESMFold_advanced.ipynb) for more advanced options (like sampling).\n",
        "\n",
        "#### **Colab Limitations**\n",
        "- For short monomeric proteins under the length 400, consider using [ESMFold API](https://esmatlas.com/resources?action=fold) (no need for GPU, super fast!)\n",
        "- On Tesla T4 (typical free colab GPU), max total length ~ 900"
      ],
      "metadata": {
        "id": "POQBeXf2Xoxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seeq = 'GSGSGSCVKWFIYGVIAVYICYTLIVHKRYQEKEELTSSVRVTLKGVAHVDRIWDAAEYTIPTQTRDSFFVMTNIIRTENQIQKTCPEYPTAKAICSSDKSCAKGIVDVHSNGVQTGKCVHYNITHKTCEIKAWCPVQGEERPPVPAVLRSSEDFTVFIKNNIHFPTFQYTVQNISPKLNTSCKFNKVTAPLCPIFRLGDILQEAKENFSEMAVKGGIIAIEIKWDCDLDSWSYYCSPEYSFRRLDDKTRTQYPGFSIRFARHYKLPDGTEQRTLFKAYGIRFDVLVFGMGGQFKLIELFTFIGSTIAYFGLAVTIIEMCFHLYNLE'"
      ],
      "metadata": {
        "id": "SjEvOqrIVS_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seeq[101:166]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Yhzy9S4AVXA5",
        "outputId": "73e07319-75a3-48b8-90a9-9a23103ca0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CAKGIVDVHSNGVQTGKCVHYNITHKTCEIKAWCPVQGEERPPVPAVLRSSEDFTVFIKNNIHFP'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boFQEwsNQ4Qt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235b2bd2-7b81-4585-b437-3fe4ad5dc8c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 73 µs, sys: 0 ns, total: 73 µs\n",
            "Wall time: 49.4 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#@title install\n",
        "#@markdown install ESMFold, OpenFold and download Params (~2min 30s)\n",
        "\n",
        "import os, time\n",
        "if not os.path.isfile(\"esmfold.model\"):\n",
        "  # download esmfold params\n",
        "  os.system(\"apt-get install aria2 -qq\")\n",
        "  os.system(\"aria2c -q -x 16 https://colabfold.steineggerlab.workers.dev/esm/esmfold.model &\")\n",
        "\n",
        "  # install libs\n",
        "  os.system(\"pip install -q omegaconf pytorch_lightning biopython ml_collections einops py3Dmol\")\n",
        "  os.system(\"pip install -q git+https://github.com/NVIDIA/dllogger.git\")\n",
        "\n",
        "  # install openfold\n",
        "  commit = \"6908936b68ae89f67755240e2f588c09ec31d4c8\"\n",
        "  os.system(f\"pip install -q git+https://github.com/aqlaboratory/openfold.git@{commit}\")\n",
        "\n",
        "  # install esmfold\n",
        "  os.system(f\"pip install -q git+https://github.com/sokrypton/esm.git\")\n",
        "\n",
        "  # wait for Params to finish downloading...\n",
        "  if not os.path.isfile(\"esmfold.model\"):\n",
        "    # backup source!\n",
        "    os.system(\"aria2c -q -x 16 https://files.ipd.uw.edu/pub/esmfold/esmfold.model\")\n",
        "  else:\n",
        "    while os.path.isfile(\"esmfold.model.aria2\"):\n",
        "      time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##import libraries\n",
        "\n",
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 128\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "#   size using a transformer.\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 1\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 1000\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0001\n",
        "\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1\n",
        "\n",
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1QPlQSJffPC",
        "outputId": "48fedb72-6ccf-4aad-fddd-74ccf29be5b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##Generator\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 5, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 5 x 5\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 5, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 10 x 10\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, (4,3), (1,2), (0,1), bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 10 x 20\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, (4,3), (1,2), (0,1), bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 20 x 40\n",
        "            nn.ConvTranspose2d( ngf, nc, (4,3), (1,2), (0,1), bias=False),\n",
        "            # state size. (nc) x 20 x 80\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "netG = Generator(ngpu).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.02.\n",
        "netG.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "print(netG)\n",
        "\n",
        "# Initialize BCELoss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Create batch of latent vectors that we will use to visualize\n",
        "#  the progression of the generator\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV0-60-OgWhp",
        "outputId": "1b8bb4b2-07c0-4587-c130-97d331ed6712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 3), stride=(1, 2), padding=(0, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 3), stride=(1, 2), padding=(0, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 1, kernel_size=(4, 3), stride=(1, 2), padding=(0, 1), bias=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "noise = torch.randn(1, nz, 1, 1, device=device)\n",
        "fake = netG(noise)\n",
        "plt.imshow(fake.cpu().detach().numpy()[0][0])\n",
        "print(fake.cpu().detach().numpy().shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "I6_hppZAgoC5",
        "outputId": "7e9447f1-9530-4b63-c40d-3c57c6e32696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 20, 81)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "\n",
        "\n",
        "aa = 'A R N D C E Q G H I L K M F P S T W Y V'\n",
        "aminoacid_list = aa.split(' ')\n",
        "a_dict={}\n",
        "for i, aaa in enumerate(aminoacid_list):\n",
        "  a_dict[aaa]=i\n",
        "\n",
        "\n",
        "def numpy_to_seq(array, seq_len, oligomer=1):\n",
        "  sequence = []\n",
        "  receptor = seeq\n",
        "  array = array.cpu().detach().numpy()\n",
        "  for i in array:\n",
        "    seq=''\n",
        "    array_n = i[0]\n",
        "    for i in array_n.T:\n",
        "      z = np.argmax(i)\n",
        "      seq+=aminoacid_list[z]\n",
        "    seq = seq[:seq_len]\n",
        "    seq = seq + ('/' + receptor)\n",
        "    sequence.append(seq)\n",
        "  return sequence\n",
        "\n",
        "\n",
        "def take_loss(target_pdb_name, seq_len):\n",
        "  all_loss = [take_loss1(f'{target_pdb_name}{i}.pdb') for i in range(seq_len)]\n",
        "  target = [0 for i in range(seq_len)]\n",
        "  return torch.tensor(target).float(), torch.tensor(all_loss).float()\n",
        "\n",
        "\n",
        "def take_loss1(filename):\n",
        "  with open(filename) as ifile:\n",
        "      system = \"\".join([x for x in ifile])\n",
        "  system1 = system.split(\"\\n\")\n",
        "  system2 = []\n",
        "  for x in system1:\n",
        "    if x[:4] == 'ATOM':\n",
        "      system2.append(x)\n",
        "  CAS = [x for x in system2 if \"CA\" in x]\n",
        "  CAS = [x.split(' ') for x in CAS]\n",
        "  CAS = [[x for x in y if x!=''] for y in CAS ]\n",
        "  CAS_A = [x for x in CAS if x[4]=='A']\n",
        "  CAS_B = [x for x in CAS if x[4]=='B']\n",
        "  CAS_B = CAS_B[111:116] + CAS_B[158:166] + CAS_B[271:276]\n",
        "  CAS_A = np.array([np.array([float(x[6]), float(x[7]), float(x[8])]) for x in CAS_A])\n",
        "  CAS_B = np.array([np.array([float(x[6]), float(x[7]), float(x[8])]) for x in CAS_B])\n",
        "  loss = sum([sqrt(np.sum((CAS_A - i)**2))/CAS_A.shape[0] for i in CAS_B])/CAS_B.shape[0]\n",
        "  return loss"
      ],
      "metadata": {
        "id": "PfrvehzUg3Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##run **ESMFold**\n",
        "from string import ascii_uppercase, ascii_lowercase\n",
        "import hashlib, re, os\n",
        "import numpy as np\n",
        "from jax.tree_util import tree_map\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "\n",
        "def ESM_fold(seq, id):\n",
        "  def parse_output(output):\n",
        "    pae = (output[\"aligned_confidence_probs\"][0] * np.arange(64)).mean(-1) * 31\n",
        "    plddt = output[\"plddt\"][0,:,1]\n",
        "    \n",
        "    bins = np.append(0,np.linspace(2.3125,21.6875,63))\n",
        "    sm_contacts = softmax(output[\"distogram_logits\"],-1)[0]\n",
        "    sm_contacts = sm_contacts[...,bins<8].sum(-1)\n",
        "    xyz = output[\"positions\"][-1,0,:,1]\n",
        "    mask = output[\"atom37_atom_exists\"][0,:,1] == 1\n",
        "    o = {\"pae\":pae[mask,:][:,mask],\n",
        "        \"plddt\":plddt[mask],\n",
        "        \"sm_contacts\":sm_contacts[mask,:][:,mask],\n",
        "        \"xyz\":xyz[mask]}\n",
        "    return o\n",
        "\n",
        "  def get_hash(x): return hashlib.sha1(x.encode()).hexdigest()\n",
        "  alphabet_list = list(ascii_uppercase+ascii_lowercase)\n",
        "\n",
        "  jobname = \"test\"\n",
        "  jobname = re.sub(r'\\W+', '', jobname)[:50]\n",
        "\n",
        "  sequence = seq\n",
        "  sequence = re.sub(\"[^A-Z:]\", \"\", sequence.replace(\"/\",\":\").upper())\n",
        "  sequence = re.sub(\":+\",\":\",sequence)\n",
        "  sequence = re.sub(\"^[:]+\",\"\",sequence)\n",
        "  sequence = re.sub(\"[:]+$\",\"\",sequence)\n",
        "  copies = 1\n",
        "  if copies == \"\" or copies <= 0: copies = 1\n",
        "  sequence = \":\".join([sequence] * copies)\n",
        "  num_recycles = 3\n",
        "  chain_linker = 25 \n",
        "\n",
        "  ID = id\n",
        "  seqs = sequence.split(\":\")\n",
        "  lengths = [len(s) for s in seqs]\n",
        "  length = sum(lengths)\n",
        "  print(\"length\",length)\n",
        "\n",
        "  u_seqs = list(set(seqs))\n",
        "  if len(seqs) == 1: mode = \"mono\"\n",
        "  elif len(u_seqs) == 1: mode = \"homo\"\n",
        "  else: mode = \"hetero\"\n",
        "\n",
        "  if \"model\" not in dir():\n",
        "    import torch\n",
        "    model = torch.load(\"esmfold.model\")\n",
        "    model.eval().cuda().requires_grad_(False)\n",
        "\n",
        "  # optimized for Tesla T4\n",
        "  if length > 700:\n",
        "    model.set_chunk_size(64)\n",
        "  else:\n",
        "    model.set_chunk_size(128)\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "  output = model.infer(sequence,\n",
        "                      num_recycles=num_recycles,\n",
        "                      chain_linker=\"X\"*chain_linker,\n",
        "                      residue_index_offset=512)\n",
        "\n",
        "  pdb_str = model.output_to_pdb(output)[0]\n",
        "  output = tree_map(lambda x: x.cpu().numpy(), output)\n",
        "  ptm = output[\"ptm\"][0]\n",
        "  plddt = output[\"plddt\"][0,...,1].mean()\n",
        "  O = parse_output(output)\n",
        "  print(f'ptm: {ptm:.3f} plddt: {plddt:.3f}')\n",
        "  prefix = f\"{ID}\"\n",
        "  with open(f\"{prefix}.pdb\",\"w\") as out:\n",
        "    out.write(pdb_str)"
      ],
      "metadata": {
        "id": "CcyNpAvhTX6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ESM_fold(numpy_to_seq(fake,10)[0],1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPEUvNQvljLz",
        "outputId": "86c1a812-8563-4efd-e274-31401cae5c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length 337\n",
            "ptm: 0.675 plddt: 75.299\n",
            "CPU times: user 24.4 s, sys: 33.7 s, total: 58.1 s\n",
            "Wall time: 1min 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import re\n",
        "from string import ascii_uppercase, ascii_lowercase"
      ],
      "metadata": {
        "id": "D6dIRtUEjZOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "num_epochs = 20\n",
        "copies = 10\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "#tables=[]\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "# For each epoch\n",
        "netG.apply(weights_init)\n",
        "for epoch in range(num_epochs):\n",
        "      start = time.time()\n",
        "    # For each batch in the dataloader\n",
        "      noise = torch.randn(copies, nz, 1, 1, device=device)\n",
        "\n",
        "      fake = netG(noise)\n",
        "      fake = numpy_to_seq(fake, 10)\n",
        "      img_list.append(fake)\n",
        "      for i, x in enumerate(fake):\n",
        "        ESM_fold(x, i)\n",
        "      \n",
        "      optimizerG.zero_grad()\n",
        "      \n",
        "      # Calculate G's loss based on this output\n",
        "      target, pred_loss = take_loss('', copies)\n",
        "      errG = criterion(target, pred_loss).requires_grad_(True)\n",
        "      print(errG)\n",
        "      # Calculate gradients for G\n",
        "      errG.backward()\n",
        "      # Update G\n",
        "      optimizerG.step()\n",
        "        \n",
        "      # Output training stats\n",
        "      print(f'{epoch+1}/{num_epochs}, {errG.item()}')\n",
        "      #tables.append(fake.detach().numpy()[0][0])\n",
        "      \n",
        "      # Save Losses for plotting later\n",
        "      G_losses.append(errG.item())\n",
        "      print('time:', time.time()-start)\n",
        "#tables.append(fake.detach().numpy()[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "29_lFZxtjcai",
        "outputId": "b17e3211-c0b4-4c92-fc87-341e46c1f833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training Loop...\n",
            "length 337\n",
            "ptm: 0.752 plddt: 83.390\n",
            "length 337\n",
            "ptm: 0.768 plddt: 84.674\n",
            "length 337\n",
            "ptm: 0.767 plddt: 83.932\n",
            "length 337\n",
            "ptm: 0.675 plddt: 75.243\n",
            "length 337\n",
            "ptm: 0.689 plddt: 76.619\n",
            "length 337\n",
            "ptm: 0.675 plddt: 74.859\n",
            "length 337\n",
            "ptm: 0.753 plddt: 83.998\n",
            "length 337\n",
            "ptm: 0.759 plddt: 84.041\n",
            "length 337\n",
            "ptm: 0.672 plddt: 75.341\n",
            "length 337\n",
            "ptm: 0.666 plddt: 74.424\n",
            "length 337\n",
            "ptm: 0.677 plddt: 75.276\n",
            "length 337\n",
            "ptm: 0.705 plddt: 78.006\n",
            "length 337\n",
            "ptm: 0.681 plddt: 76.385\n",
            "length 337\n",
            "ptm: 0.759 plddt: 83.723\n",
            "length 337\n",
            "ptm: 0.768 plddt: 85.217\n",
            "length 337\n",
            "ptm: 0.684 plddt: 75.650\n",
            "length 337\n",
            "ptm: 0.676 plddt: 75.667\n",
            "length 337\n",
            "ptm: 0.689 plddt: 76.393\n",
            "length 337\n",
            "ptm: 0.686 plddt: 75.949\n",
            "length 337\n",
            "ptm: 0.681 plddt: 76.145\n",
            "tensor(275.4329, requires_grad=True)\n",
            "1/10, 275.432861328125\n",
            "time: 1898.8197014331818\n",
            "length 337\n",
            "ptm: 0.766 plddt: 84.203\n",
            "length 337\n",
            "ptm: 0.741 plddt: 82.134\n",
            "length 337\n",
            "ptm: 0.682 plddt: 75.534\n",
            "length 337\n",
            "ptm: 0.765 plddt: 85.035\n",
            "length 337\n",
            "ptm: 0.677 plddt: 75.189\n",
            "length 337\n",
            "ptm: 0.771 plddt: 85.279\n",
            "length 337\n",
            "ptm: 0.721 plddt: 79.914\n",
            "length 337\n",
            "ptm: 0.758 plddt: 84.187\n",
            "length 337\n",
            "ptm: 0.707 plddt: 78.387\n",
            "length 337\n",
            "ptm: 0.685 plddt: 76.162\n",
            "length 337\n",
            "ptm: 0.709 plddt: 79.374\n",
            "length 337\n",
            "ptm: 0.705 plddt: 77.977\n",
            "length 337\n",
            "ptm: 0.676 plddt: 75.071\n",
            "length 337\n",
            "ptm: 0.685 plddt: 75.899\n",
            "length 337\n",
            "ptm: 0.764 plddt: 84.999\n",
            "length 337\n",
            "ptm: 0.764 plddt: 84.527\n",
            "length 337\n",
            "ptm: 0.680 plddt: 76.000\n",
            "length 337\n",
            "ptm: 0.680 plddt: 75.738\n",
            "length 337\n",
            "ptm: 0.761 plddt: 84.539\n",
            "length 337\n",
            "ptm: 0.682 plddt: 75.171\n",
            "tensor(269.2142, requires_grad=True)\n",
            "2/10, 269.2142333984375\n",
            "time: 1922.6558690071106\n",
            "length 337\n",
            "ptm: 0.765 plddt: 84.601\n",
            "length 337\n",
            "ptm: 0.762 plddt: 84.170\n",
            "length 337\n",
            "ptm: 0.681 plddt: 75.995\n",
            "length 337\n",
            "ptm: 0.679 plddt: 75.923\n",
            "length 337\n",
            "ptm: 0.763 plddt: 84.008\n",
            "length 337\n",
            "ptm: 0.671 plddt: 75.395\n",
            "length 337\n",
            "ptm: 0.753 plddt: 83.879\n",
            "length 337\n",
            "ptm: 0.763 plddt: 83.776\n",
            "length 337\n",
            "ptm: 0.685 plddt: 76.254\n",
            "length 337\n",
            "ptm: 0.682 plddt: 75.990\n",
            "length 337\n",
            "ptm: 0.676 plddt: 74.993\n",
            "length 337\n",
            "ptm: 0.678 plddt: 75.856\n",
            "length 337\n",
            "ptm: 0.757 plddt: 83.995\n",
            "length 337\n",
            "ptm: 0.675 plddt: 75.596\n",
            "length 337\n",
            "ptm: 0.755 plddt: 83.244\n",
            "length 337\n",
            "ptm: 0.742 plddt: 82.193\n",
            "length 337\n",
            "ptm: 0.678 plddt: 74.962\n",
            "length 337\n",
            "ptm: 0.680 plddt: 75.380\n",
            "length 337\n",
            "ptm: 0.769 plddt: 84.952\n",
            "length 337\n",
            "ptm: 0.670 plddt: 74.692\n",
            "tensor(252.6396, requires_grad=True)\n",
            "3/10, 252.63955688476562\n",
            "time: 1934.2766456604004\n",
            "length 337\n",
            "ptm: 0.763 plddt: 84.188\n",
            "length 337\n",
            "ptm: 0.672 plddt: 74.994\n",
            "length 337\n",
            "ptm: 0.680 plddt: 75.646\n",
            "length 337\n",
            "ptm: 0.676 plddt: 75.389\n",
            "length 337\n",
            "ptm: 0.760 plddt: 84.826\n",
            "length 337\n",
            "ptm: 0.679 plddt: 75.872\n",
            "length 337\n",
            "ptm: 0.679 plddt: 75.544\n",
            "length 337\n",
            "ptm: 0.759 plddt: 84.053\n",
            "length 337\n",
            "ptm: 0.690 plddt: 76.575\n",
            "length 337\n",
            "ptm: 0.675 plddt: 75.425\n",
            "length 337\n",
            "ptm: 0.679 plddt: 76.153\n",
            "length 337\n",
            "ptm: 0.757 plddt: 83.090\n",
            "length 337\n",
            "ptm: 0.685 plddt: 76.268\n",
            "length 337\n",
            "ptm: 0.760 plddt: 84.407\n",
            "length 337\n",
            "ptm: 0.674 plddt: 75.187\n",
            "length 337\n",
            "ptm: 0.685 plddt: 75.863\n",
            "length 337\n",
            "ptm: 0.680 plddt: 76.074\n",
            "length 337\n",
            "ptm: 0.669 plddt: 73.849\n",
            "length 337\n",
            "ptm: 0.761 plddt: 84.323\n",
            "length 337\n",
            "ptm: 0.766 plddt: 84.688\n",
            "tensor(275.2201, requires_grad=True)\n",
            "4/10, 275.2201232910156\n",
            "time: 1933.1115872859955\n",
            "length 337\n",
            "ptm: 0.760 plddt: 84.134\n",
            "length 337\n",
            "ptm: 0.733 plddt: 80.688\n",
            "length 337\n",
            "ptm: 0.683 plddt: 76.230\n",
            "length 337\n",
            "ptm: 0.673 plddt: 75.094\n",
            "length 337\n",
            "ptm: 0.769 plddt: 84.922\n",
            "length 337\n",
            "ptm: 0.757 plddt: 83.394\n",
            "length 337\n",
            "ptm: 0.678 plddt: 75.570\n",
            "length 337\n",
            "ptm: 0.762 plddt: 84.676\n",
            "length 337\n",
            "ptm: 0.682 plddt: 75.736\n",
            "length 337\n",
            "ptm: 0.682 plddt: 75.882\n",
            "length 337\n",
            "ptm: 0.765 plddt: 84.909\n",
            "length 337\n",
            "ptm: 0.674 plddt: 75.124\n",
            "length 337\n",
            "ptm: 0.771 plddt: 84.898\n",
            "length 337\n",
            "ptm: 0.756 plddt: 84.038\n",
            "length 337\n",
            "ptm: 0.763 plddt: 83.980\n",
            "length 337\n",
            "ptm: 0.677 plddt: 75.933\n",
            "length 337\n",
            "ptm: 0.674 plddt: 75.260\n",
            "length 337\n",
            "ptm: 0.761 plddt: 84.882\n",
            "length 337\n",
            "ptm: 0.685 plddt: 76.070\n",
            "length 337\n",
            "ptm: 0.684 plddt: 75.148\n",
            "tensor(263.3672, requires_grad=True)\n",
            "5/10, 263.3671875\n",
            "time: 1933.4830186367035\n",
            "length 337\n",
            "ptm: 0.683 plddt: 75.571\n",
            "length 337\n",
            "ptm: 0.675 plddt: 75.182\n",
            "length 337\n",
            "ptm: 0.679 plddt: 75.855\n",
            "length 337\n",
            "ptm: 0.674 plddt: 74.663\n",
            "length 337\n",
            "ptm: 0.685 plddt: 75.765\n",
            "length 337\n",
            "ptm: 0.685 plddt: 76.393\n",
            "length 337\n",
            "ptm: 0.688 plddt: 76.491\n",
            "length 337\n",
            "ptm: 0.758 plddt: 84.723\n",
            "length 337\n",
            "ptm: 0.680 plddt: 75.996\n",
            "length 337\n",
            "ptm: 0.717 plddt: 79.280\n",
            "length 337\n",
            "ptm: 0.759 plddt: 83.683\n",
            "length 337\n",
            "ptm: 0.749 plddt: 83.722\n",
            "length 337\n",
            "ptm: 0.681 plddt: 76.141\n",
            "length 337\n",
            "ptm: 0.680 plddt: 75.423\n",
            "length 337\n",
            "ptm: 0.684 plddt: 76.230\n",
            "length 337\n",
            "ptm: 0.678 plddt: 75.575\n",
            "length 337\n",
            "ptm: 0.762 plddt: 84.984\n",
            "length 337\n",
            "ptm: 0.685 plddt: 75.986\n",
            "length 337\n",
            "ptm: 0.684 plddt: 76.144\n",
            "length 337\n",
            "ptm: 0.678 plddt: 75.572\n",
            "tensor(286.7726, requires_grad=True)\n",
            "6/10, 286.7725524902344\n",
            "time: 1916.1973328590393\n",
            "length 337\n",
            "ptm: 0.670 plddt: 75.172\n",
            "length 337\n",
            "ptm: 0.682 plddt: 76.508\n",
            "length 337\n",
            "ptm: 0.685 plddt: 76.019\n",
            "length 337\n",
            "ptm: 0.679 plddt: 75.400\n",
            "length 337\n",
            "ptm: 0.709 plddt: 78.678\n",
            "length 337\n",
            "ptm: 0.688 plddt: 76.402\n",
            "length 337\n",
            "ptm: 0.689 plddt: 76.456\n",
            "length 337\n",
            "ptm: 0.758 plddt: 83.966\n",
            "length 337\n",
            "ptm: 0.763 plddt: 84.729\n",
            "length 337\n",
            "ptm: 0.764 plddt: 84.050\n",
            "length 337\n",
            "ptm: 0.764 plddt: 84.165\n",
            "length 337\n",
            "ptm: 0.683 plddt: 76.135\n",
            "length 337\n",
            "ptm: 0.670 plddt: 74.280\n",
            "length 337\n",
            "ptm: 0.689 plddt: 76.197\n",
            "length 337\n",
            "ptm: 0.713 plddt: 80.094\n",
            "length 337\n",
            "ptm: 0.672 plddt: 75.772\n",
            "length 337\n",
            "ptm: 0.672 plddt: 74.581\n",
            "length 337\n",
            "ptm: 0.675 plddt: 74.847\n",
            "length 337\n",
            "ptm: 0.681 plddt: 75.480\n",
            "length 337\n",
            "ptm: 0.673 plddt: 74.837\n",
            "tensor(293.9611, requires_grad=True)\n",
            "7/10, 293.96112060546875\n",
            "time: 1912.8519384860992\n",
            "length 337\n",
            "ptm: 0.758 plddt: 84.393\n",
            "length 337\n",
            "ptm: 0.682 plddt: 75.676\n",
            "length 337\n",
            "ptm: 0.680 plddt: 75.707\n",
            "length 337\n",
            "ptm: 0.764 plddt: 83.993\n",
            "length 337\n",
            "ptm: 0.679 plddt: 75.313\n",
            "length 337\n",
            "ptm: 0.670 plddt: 75.327\n",
            "length 337\n",
            "ptm: 0.676 plddt: 75.776\n",
            "length 337\n",
            "ptm: 0.767 plddt: 84.701\n",
            "length 337\n",
            "ptm: 0.675 plddt: 75.607\n",
            "length 337\n",
            "ptm: 0.757 plddt: 84.198\n",
            "length 337\n",
            "ptm: 0.681 plddt: 75.637\n",
            "length 337\n",
            "ptm: 0.679 plddt: 75.845\n",
            "length 337\n",
            "ptm: 0.683 plddt: 76.066\n",
            "length 337\n",
            "ptm: 0.676 plddt: 74.701\n",
            "length 337\n",
            "ptm: 0.672 plddt: 74.565\n",
            "length 337\n",
            "ptm: 0.762 plddt: 84.197\n",
            "length 337\n",
            "ptm: 0.682 plddt: 75.732\n",
            "length 337\n",
            "ptm: 0.679 plddt: 75.558\n",
            "length 337\n",
            "ptm: 0.762 plddt: 84.297\n",
            "length 337\n",
            "ptm: 0.754 plddt: 83.943\n",
            "tensor(292.9890, requires_grad=True)\n",
            "8/10, 292.98895263671875\n",
            "time: 1921.682079076767\n",
            "length 337\n",
            "ptm: 0.680 plddt: 75.253\n",
            "length 337\n",
            "ptm: 0.680 plddt: 75.777\n",
            "length 337\n",
            "ptm: 0.678 plddt: 75.279\n",
            "length 337\n",
            "ptm: 0.758 plddt: 85.081\n",
            "length 337\n",
            "ptm: 0.754 plddt: 83.581\n",
            "length 337\n",
            "ptm: 0.683 plddt: 75.779\n",
            "length 337\n",
            "ptm: 0.677 plddt: 74.798\n",
            "length 337\n",
            "ptm: 0.685 plddt: 76.809\n",
            "length 337\n",
            "ptm: 0.682 plddt: 75.770\n",
            "length 337\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-92036aad020e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mimg_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mESM_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0moptimizerG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-f8c9d4a0db07>\u001b[0m in \u001b[0;36mESM_fold\u001b[0;34m(seq, id)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m\"model\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"esmfold.model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'data/{key}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UntypedStorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untyped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0;31m# TODO: Once we decide to break serialization FC, we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0;31m# stop wrapping with _TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(190*10)/60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92V5eOpNo-KM",
        "outputId": "53c2f1bd-8997-486b-c5b8-a1bfc290b4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31.666666666666668"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title display (optional) {run: \"auto\"}\n",
        "import py3Dmol\n",
        "pymol_color_list = [\"#33ff33\",\"#00ffff\",\"#ff33cc\",\"#ffff00\",\"#ff9999\",\"#e5e5e5\",\"#7f7fff\",\"#ff7f00\",\n",
        "                    \"#7fff7f\",\"#199999\",\"#ff007f\",\"#ffdd5e\",\"#8c3f99\",\"#b2b2b2\",\"#007fff\",\"#c4b200\",\n",
        "                    \"#8cb266\",\"#00bfbf\",\"#b27f7f\",\"#fcd1a5\",\"#ff7f7f\",\"#ffbfdd\",\"#7fffff\",\"#ffff7f\",\n",
        "                    \"#00ff7f\",\"#337fcc\",\"#d8337f\",\"#bfff3f\",\"#ff7fff\",\"#d8d8ff\",\"#3fffbf\",\"#b78c4c\",\n",
        "                    \"#339933\",\"#66b2b2\",\"#ba8c84\",\"#84bf00\",\"#b24c66\",\"#7f7f7f\",\"#3f3fa5\",\"#a5512b\"]\n",
        "\n",
        "def show_pdb(pdb_str, show_sidechains=False, show_mainchains=False,\n",
        "             color=\"pLDDT\", chains=None, vmin=50, vmax=90,\n",
        "             size=(800,480), hbondCutoff=4.0,\n",
        "             Ls=None,\n",
        "             animate=False):\n",
        "  alphabet_list = list(ascii_uppercase+ascii_lowercase)\n",
        "  if chains is None:\n",
        "    chains = 1 if Ls is None else len(Ls)\n",
        "  view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js', width=size[0], height=size[1])\n",
        "  if animate:\n",
        "    view.addModelsAsFrames(pdb_str,'pdb',{'hbondCutoff':hbondCutoff})\n",
        "  else:\n",
        "    view.addModel(pdb_str,'pdb',{'hbondCutoff':hbondCutoff})\n",
        "  if color == \"pLDDT\":\n",
        "    view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':vmin,'max':vmax}}})\n",
        "  elif color == \"rainbow\":\n",
        "    view.setStyle({'cartoon': {'color':'spectrum'}})\n",
        "  elif color == \"chain\":\n",
        "    for n,chain,color in zip(range(chains),alphabet_list,pymol_color_list):\n",
        "       view.setStyle({'chain':chain},{'cartoon': {'color':color}})\n",
        "  if show_sidechains:\n",
        "    BB = ['C','O','N']\n",
        "    view.addStyle({'and':[{'resn':[\"GLY\",\"PRO\"],'invert':True},{'atom':BB,'invert':True}]},\n",
        "                  {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"GLY\"},{'atom':'CA'}]},\n",
        "                  {'sphere':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"PRO\"},{'atom':['C','O'],'invert':True}]},\n",
        "                  {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})  \n",
        "  if show_mainchains:\n",
        "    BB = ['C','O','N','CA']\n",
        "    view.addStyle({'atom':BB},{'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "  view.zoomTo()\n",
        "  if animate: view.animate()\n",
        "  #view.addSurface(py3Dmol.SES,{'opacity':0.9,'color':'lightblue'})\n",
        "  return view\n",
        "\n",
        "color = \"confidence\" #@param [\"confidence\", \"rainbow\", \"chain\"]\n",
        "if color == \"confidence\": color = \"pLDDT\"\n",
        "show_sidechains = False #@param {type:\"boolean\"}\n",
        "show_mainchains = False #@param {type:\"boolean\"}\n",
        "pdb_str='1'\n",
        "show_pdb(pdb_str, color=color,\n",
        "         show_sidechains=show_sidechains,\n",
        "         show_mainchains=show_mainchains).show()"
      ],
      "metadata": {
        "id": "JM5ciSmeTZKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import py3Dmol\n",
        "with open(\"4.pdb\") as ifile:\n",
        "    system = \"\".join([x for x in ifile])\n",
        "view = py3Dmol.view(width=400, height=400)\n",
        "view.addModelsAsFrames(system)\n",
        "view.setStyle({},{\"cartoon\": {'color': 'spectrum'}})\n",
        "\n",
        "#view.addSurface(py3Dmol.SAS, {'model': 0, 'chain': 'A', 'opacity': 0.9})\n",
        "CA99 = [8.429,  67.609, -39.284]\n",
        "\n",
        "#view.addBox({'center':{'x':[CA99[0]],'y':[CA99[1]],'z':[CA99[2]]},'dimensions': {'w':15,'h':15,'d':15},'color':'blue','opacity': 0.7})\n",
        "#view.addSurface()\n",
        "view.zoomTo()\n",
        "view.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "p08wR6plmiNC",
        "outputId": "083b3332-4963-45c7-d56b-a59ba06ae0cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ae1b7ad50ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpy3Dmol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"4.pdb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mifile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msystem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mifile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy3Dmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddModelsAsFrames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'py3Dmol'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZtn69eJmX3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title plot confidence (optional)\n",
        "\n",
        "dpi = 100 #@param {type:\"integer\"}\n",
        "\n",
        "def plot_ticks(Ls):\n",
        "  Ln = sum(Ls)\n",
        "  L_prev = 0\n",
        "  for L_i in Ls[:-1]:\n",
        "    L = L_prev + L_i\n",
        "    L_prev += L_i\n",
        "    plt.plot([0,Ln],[L,L],color=\"black\")\n",
        "    plt.plot([L,L],[0,Ln],color=\"black\")\n",
        "  ticks = np.cumsum([0]+Ls)\n",
        "  ticks = (ticks[1:] + ticks[:-1])/2\n",
        "  plt.yticks(ticks,alphabet_list[:len(ticks)])\n",
        "\n",
        "def plot_confidence(O, Ls=None, dpi=100):\n",
        "  if \"lm_contacts\" in O:\n",
        "    plt.figure(figsize=(20,4), dpi=dpi)\n",
        "    plt.subplot(1,4,1)\n",
        "  else:\n",
        "    plt.figure(figsize=(15,4), dpi=dpi)\n",
        "    plt.subplot(1,3,1)\n",
        "\n",
        "  plt.title('Predicted lDDT')\n",
        "  plt.plot(O[\"plddt\"])\n",
        "  if Ls is not None:\n",
        "    L_prev = 0\n",
        "    for L_i in Ls[:-1]:\n",
        "      L = L_prev + L_i\n",
        "      L_prev += L_i\n",
        "      plt.plot([L,L],[0,100],color=\"black\")\n",
        "  plt.xlim(0,O[\"plddt\"].shape[0])\n",
        "  plt.ylim(0,100)\n",
        "  plt.ylabel('plDDT')\n",
        "  plt.xlabel('position')\n",
        "  plt.subplot(1,4 if \"lm_contacts\" in O else 3,2)\n",
        "\n",
        "  plt.title('Predicted Aligned Error')\n",
        "  Ln = O[\"pae\"].shape[0]\n",
        "  plt.imshow(O[\"pae\"],cmap=\"bwr\",vmin=0,vmax=30,extent=(0, Ln, Ln, 0))\n",
        "  if Ls is not None and len(Ls) > 1: plot_ticks(Ls)\n",
        "  plt.colorbar()\n",
        "  plt.xlabel('Scored residue')\n",
        "  plt.ylabel('Aligned residue')\n",
        "\n",
        "  if \"lm_contacts\" in O:\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.title(\"contacts from LM\")\n",
        "    plt.imshow(O[\"lm_contacts\"],cmap=\"Greys\",vmin=0,vmax=1,extent=(0, Ln, Ln, 0))\n",
        "    if Ls is not None and len(Ls) > 1: plot_ticks(Ls)\n",
        "    plt.subplot(1,4,4)\n",
        "  else:\n",
        "    plt.subplot(1,3,3)\n",
        "  plt.title(\"contacts from Structure Module\")\n",
        "  plt.imshow(O[\"sm_contacts\"],cmap=\"Greys\",vmin=0,vmax=1,extent=(0, Ln, Ln, 0))\n",
        "  if Ls is not None and len(Ls) > 1: plot_ticks(Ls)\n",
        "  return plt\n",
        "\n",
        "plot_confidence(O, Ls=lengths, dpi=dpi)\n",
        "plt.savefig(f'{prefix}.png',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HGFBl0QYYQpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title download predictions\n",
        "from google.colab import files\n",
        "os.system(f\"zip {ID}.zip {ID}/*\")\n",
        "files.download(f'{ID}.zip')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hkMp_ZwRYfAQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}